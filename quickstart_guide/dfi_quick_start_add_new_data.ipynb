{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide - Adding Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will guide you inserting data into the the Platform from\n",
    "[General System](https://www.generalsystem.com).\n",
    "\n",
    "OpenAPI specification documentation is available at\n",
    "<https://api.dataflowindex.io/docs/api>.\n",
    "\n",
    "Please refer to https://github.com/thegeneralsystem/dfi-client-examples for\n",
    "the most up-to-date companion documentation.\n",
    "\n",
    "Additional resources and help are available at <https://support.generalsystem.com>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python modules if they are not already present.\n",
    "!python3 -m pip install requests tabulate pydeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules.\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set your API token to access the DFI API.\n",
    "#\n",
    "# Access to the DFI demonstration servers requires an API token, which may be\n",
    "# obtained free of charge by enrolling at <https://eap.generalsystem.com>. Once\n",
    "# enrolled, your API token may be redeemed from <https://tokens.dataflowindex.io/>.\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "api_token = getpass(\"Enter your API token: \")\n",
    "\n",
    "# Set authorisation headers:\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "base_url = \"https://api.dataflowindex.io\"\n",
    "query_timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of instances associated with your API token.\n",
    "r = requests.get(f\"{base_url}/instances\", headers=headers, timeout=query_timeout)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next select which DFI instance you will be accessing.\n",
    "# Insert the name of your DFI instance here.\n",
    "# Contact support via https://support.generalsystem.com/ if you need help\n",
    "# finding your DFI instance name.\n",
    "instance_name = \"YOUR_DFI_INSTANCE_NAME_HERE\"\n",
    "params = {\"instance\": instance_name}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data\n",
    "\n",
    "Note that you cannot add data to the Demo instance, as it is shared among multiple evaluation users.\n",
    "\n",
    "If you have access to your own Trial instance, or have purchased an instance, then you can use the methods below to add data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new point at coordinates 0,0 with sensor ID \"1\"\n",
    "# and an ID can be either an int64 or a uuidv4.\n",
    "payload = [\n",
    "    {\n",
    "        \"coordinate\": [0, 0],  # [Long, Lat ],\n",
    "        \"time\": \"2022-09-01T17:32:28.250Z\",\n",
    "        \"id\": 1234,\n",
    "        \"payload\": \"Application specific data\",\n",
    "    }\n",
    "]\n",
    "r = requests.post(f\"{base_url}/insert\", params=params, json=payload, headers=headers, timeout=query_timeout)\n",
    "\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "print(f\"Response:\\n{r.text}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a set of random points in the bounding box of any given polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a helper function.\n",
    "def create_points_in_polygon(query_polygon: str, entity_id: int, n: int) -> None:\n",
    "    r = requests.get(base_url + \"/polygons/\" + query_polygon, headers=headers, timeout=query_timeout)\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Status code: {r.status_code}\")\n",
    "        print(f\"Reason: {r.reason}\")\n",
    "        print(f\"Polygon does not exist: {query_polygon}\")\n",
    "        return None\n",
    "\n",
    "    min_lat = min([x[1] for x in r.json()[\"vertices\"]])\n",
    "    max_lat = max([x[1] for x in r.json()[\"vertices\"]])\n",
    "    min_long = min([x[0] for x in r.json()[\"vertices\"]])\n",
    "    max_long = max([x[0] for x in r.json()[\"vertices\"]])\n",
    "    print(f\"Bounding box: {min_long},{max_long} : {min_lat},{max_lat}\")\n",
    "\n",
    "    for _ in range(n):\n",
    "        payload = [\n",
    "            {\n",
    "                \"coordinate\": [random.uniform(min_long, max_long), random.uniform(min_lat, max_lat)],  # [ Long, Lat ]\n",
    "                \"time\": \"2022-01-01T\" + str(random.randint(10, 22)) + \":32:28.250Z\",\n",
    "                \"id\": entity_id,\n",
    "                \"payload\": \"Pts in polygon\",\n",
    "            }\n",
    "        ]\n",
    "        r = requests.post(f\"{base_url}/insert\", params=params, json=payload, headers=headers, timeout=query_timeout)\n",
    "        print(f\"Status code: {r.status_code}\")\n",
    "        print(f\"Response:\\n{r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created a set of interesting polygons that you can use.\n",
    "# These include the London Borough areas,\n",
    "# the Congestion Charging Zone area and more.\n",
    "# The code below lists the polygons available:\n",
    "r = requests.get(f\"{base_url}/polygons\", headers=headers, timeout=query_timeout)\n",
    "if r.status_code != 200:\n",
    "    print(f\"Status code: {r.status_code}\")\n",
    "    print(f\"Response:\\n{r.text}\")\n",
    "    r.raise_for_status()\n",
    "\n",
    "data = [[polygon[\"name\"], polygon[\"count\"]] for polygon in r.json()[\"polygons\"]]\n",
    "print(tabulate(data, [\"name\", \"vertices\"], tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some data:\n",
    "create_points_in_polygon(\"uk_southwark\", 1, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest file\n",
    "\n",
    "Ingest data from a file stored on an AWS S3 bucket (or other file accessible from the Internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before loading new data, let's DELETE all data in the instance\n",
    "truncate_headers = {\"Authorization\": f\"Bearer {api_token}\", \"accept\": \"*.*\"}\n",
    "instance_to_truncate = \"my_instance\"\n",
    "r = requests.post(\n",
    "    f\"{base_url}/instances/{instance_to_truncate}/truncate\", headers=truncate_headers, timeout=query_timeout\n",
    ")\n",
    "\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "print(f\"Response:\\n{r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check instance is empty\n",
    "r = requests.get(f\"{base_url}/count\", params=params, headers=headers, timeout=query_timeout)\n",
    "if r.status_code != 200:\n",
    "    print(f\"Status code: {r.status_code}\")\n",
    "    print(f\"Response:\\n{r.text}\")\n",
    "    r.raise_for_status()\n",
    "\n",
    "total_histories = r.json()\n",
    "print(f\"Records found: {total_histories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we submit a new ingestion job\n",
    "# we can submit a list of files to ingest\n",
    "file = \"https://domain/file.ext\"\n",
    "payload = {\n",
    "    \"source\": {\"urls\": [file]},\n",
    "    # we specify the order of the columns where to find each datatype:\n",
    "    \"format\": {\"columns\": {\"entityId\": 0, \"timestamp\": 1, \"longitude\": 2, \"latitude\": 3}},\n",
    "}\n",
    "r = requests.put(f\"{base_url}/import/s3\", json=payload, params=params, headers=headers, timeout=query_timeout)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "result = r.json()\n",
    "ingestion_id = result[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check status of ingestion\n",
    "# the possible statuses are: created, started, finished\n",
    "r = requests.get(f\"{base_url}/import/s3/{ingestion_id}/status\", headers=headers, timeout=query_timeout)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "result = r.json()\n",
    "print(\"Result status: \", result[\"status\"])\n",
    "print(\"Insert count: \", result[\"insertCount\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
